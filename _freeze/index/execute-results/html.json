{
  "hash": "056f1a904d4ffb3e4a9f717761cfa161",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Materials Genomics\nsubtitle: Computational Materials Discovery\nauthor:\n  - name: Philipp Pelz\n    corresponding: true\nkeywords:\n  - Materials Science\n  - Machine Learning\n  - Computational Materials Discovery\n  - Materials Databases\n  - Crystal Structure\nabstract: |\n  This course introduces students to materials genomics, treating the periodic table\n  and the space of known crystal structures as a searchable, computable design space.\n  Students learn how materials databases are built, how atomic structure is represented\n  numerically, how structure–property relationships are learned using machine learning,\n  and how uncertainty-aware models enable accelerated materials discovery.\ndate: last-modified\nbibliography: references.bib\nnumber-sections: true\njupyter: python3\n---\n\n## Course Information\n\n**4th/5th Semester – 5 ECTS · 2h lecture + 2h exercises per week**  \n*Coordinated with “Mathematical Foundations of AI & ML” (MFML) and  \n“ML for Materials Processing & Characterization” (ML-PC)*\n\n---\n\n## Course Philosophy\n\nMaterials genomics views the periodic table and all known crystal structures as a\n**high-dimensional design space**.\n\nIn this course, students learn to:\n\n- treat materials data as a structured, learnable representation space,\n- move beyond classical descriptors toward learned representations,\n- use ML models as surrogates for quantum-mechanical calculations,\n- reason about uncertainty, stability, and discovery,\n- understand how computational screening integrates with experiments.\n\nThe course explicitly **builds on MFML**:\n\n- PCA and regression are assumed background,\n- neural networks, representation learning, and uncertainty are used, not re-derived.\n\n---\n\n## Week-by-Week Curriculum (14 weeks)\n\n### Unit I — Materials Data as a Design Space (Weeks 1–3)\n\n#### Week 1 – What is Materials Genomics?\n\n- Genomics analogy: genes → functions vs atoms → properties.\n- Structure–property–processing paradigm from a *structure-first* viewpoint.\n- Overview of major databases: Materials Project, OQMD, AFLOW, NOMAD.\n\n**Exercise:**  \nExplore Materials Project; query bandgaps, formation energies, symmetries.\n\n---\n\n#### Week 2 – Crystal structures, symmetry, and low-dimensional structure\n\n- Crystal structures as data objects.\n- Space groups, Wyckoff positions, symmetry constraints.\n- PCA as an *exploratory tool* for structural/property data (refresher).\n\n**Exercise:**  \nUse pymatgen/spglib to analyze symmetry; visualize PCA of structural features.\n\n---\n\n#### Week 3 – Materials databases & thermodynamic quantities\n\n- File formats: CIF, POSCAR, database schemas.\n- Formation energies, convex hulls, metastability.\n- What databases do *not* contain (bias, incompleteness).\n\n**Exercise:**  \nParse CIF files; compute basic structural properties; analyze stability.\n\n---\n\n### Unit II — Representations of Materials (Weeks 4–6)\n\n*(Aligned with early neural networks in MFML)*\n\n#### Week 4 – From classical descriptors to learned representations\n\n- Classical descriptors: Magpie, matminer (composition-based).\n- Limits of hand-crafted features.\n- Why representation learning matters.\n\n**Exercise:**  \nBuild a simple property predictor using classical descriptors.\n\n---\n\n#### Week 5 – Graph-based crystal representations\n\n- Crystals as graphs: nodes, edges, periodicity.\n- Intuition behind CGCNN, MEGNet (no architecture deep dive).\n- Relation to MFML neural network concepts.\n\n**Exercise:**  \nConstruct a graph representation of crystals; visualize connectivity.\n\n---\n\n#### Week 6 – Local atomic environments\n\n- Local vs global representations.\n- Coordination environments, Voronoi tessellations.\n- SOAP descriptors as a bridge to learned representations.\n\n**Exercise:**  \nCompute SOAP vectors; cluster structures in environment space.\n\n---\n\n### Unit III — Learning Structure–Property Relations (Weeks 7–9)\n\n#### Week 7 – Regression and generalization in materials data\n\n- Predicting bandgaps, elastic moduli, formation energies.\n- Bias–variance and overfitting in materials datasets.\n- Dataset size vs model complexity.\n\n**Exercise:**  \nCompare linear, random forest, and NN regressors on a materials dataset.\n\n---\n\n#### Week 8 – Neural networks for materials properties\n\n- Neural networks as universal surrogates for DFT-level properties.\n- Training pitfalls: data leakage, imbalance, extrapolation.\n- Physical interpretability concerns.\n\n**Exercise:**  \nTrain a small NN for property prediction; analyze overfitting.\n\n---\n\n#### Week 9 – Representation learning and feature discovery\n\n- Learned vs engineered features.\n- What networks “learn” about chemistry and structure.\n- Transferability across chemical systems.\n\n**Exercise:**  \nCompare performance using raw descriptors vs learned embeddings.\n\n---\n\n### Unit IV — Latent Spaces, Uncertainty, and Discovery (Weeks 10–12)\n\n#### Week 10 – Latent spaces of materials\n\n- Autoencoders and embeddings for crystal data.\n- Interpreting latent dimensions.\n- Relation to chemical intuition and structure families.\n\n**Exercise:**  \nTrain an autoencoder; visualize latent materials space.\n\n---\n\n#### Week 11 – Clustering vs discovery in materials spaces\n\n- Why clustering ≠ discovery.\n- Structure in latent space.\n- Identifying families, outliers, and anomalies.\n\n**Exercise:**  \nCompare k-means clustering with latent-space organization.\n\n---\n\n#### Week 12 – Uncertainty-aware discovery & Gaussian Processes\n\n- Aleatoric vs epistemic uncertainty.\n- Gaussian Process regression as a gold standard for uncertainty.\n- Exploration vs exploitation in materials screening.\n- Relevance to materials acceleration platforms.\n\n**Exercise:**  \nGP regression vs NN ensembles; visualize uncertainty-driven screening.\n\n---\n\n### Unit V — Constraints, Trust, and Synthesis (Weeks 13–14)\n\n#### Week 13 – Physical constraints and informed learning\n\n- Stability, charge neutrality, symmetry constraints.\n- Physics-informed ML in materials discovery.\n- Failure modes of unconstrained models.\n\n**Exercise:**  \nTrain a constrained model using penalty-based approaches.\n\n---\n\n#### Week 14 – Integration, limits, and outlook\n\n- Explainability of materials ML models.\n- What ML can and cannot discover.\n- How computational genomics meets experiment-driven workflows.\n\n**Exercise:**  \nMini-project synthesis and presentation.\n\n---\n\n## Learning Outcomes\n\nStudents completing this course will be able to:\n\n- Navigate and interrogate major materials databases.\n- Represent crystal structures using descriptors, graphs, and learned embeddings.\n- Train and evaluate ML models for predicting materials properties.\n- Understand latent spaces and their role in materials discovery.\n- Quantify and interpret uncertainty in materials predictions.\n- Apply ML to accelerate materials screening responsibly.\n- Critically assess the limits of data-driven materials discovery.\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}